import io
import re
from PIL import Image
import logging
import asyncio
from typing import AsyncGenerator,List,Iterable
from openai.types.responses import ResponseTextDeltaEvent

from agents import Agent, Runner
import gradio as gr
import matplotlib
import tiktoken
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from langchain_community.document_loaders import DirectoryLoader
import xml.etree.ElementTree as ET

# è®¾ç½® Matplotlib ä½¿ç”¨ Agg åç«¯ï¼Œé¿å… GUI è­¦å‘Š
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–å…¨å±€ä¼šè¯ä¸Šä¸‹æ–‡
conversation_history = []


def extract_python_code(text):
    """
    ä»æ–‡æœ¬ä¸­æå– Python ä»£ç å—
    """
    # æŸ¥æ‰¾ ```python å’Œ ``` ä¹‹é—´çš„ä»£ç 
    pattern = r'```(?:python)?(.*?)```'
    matches = re.findall(pattern, text, re.DOTALL)

    if matches:
        return matches[0].strip()

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»£ç å—ï¼Œåˆ™å°è¯•ç›´æ¥ä½¿ç”¨æ–‡æœ¬ï¼ˆå‡è®¾æ•´ä¸ªæ–‡æœ¬æ˜¯ä»£ç ï¼‰
    return text.strip()


def process_code(code):
    """
    å¤„ç†ä»£ç ï¼Œæ³¨é‡Šæ‰ plt.show() è°ƒç”¨
    """
    # æ›¿æ¢ plt.show() è°ƒç”¨ä¸ºæ³¨é‡Š
    code = re.sub(r'plt\.show\(\)', '# plt.show() - å·²è¢«æ³¨é‡Š', code)
    return code


def execute_plot_code(code):
    """
    æ‰§è¡Œç»˜å›¾ä»£ç å¹¶è¿”å›å›¾åƒ
    """
    try:
        # ç¡®ä¿æ‰€æœ‰å›¾å½¢å·²å…³é—­
        plt.close('all')

        # åˆ›å»ºä¸€ä¸ªå±€éƒ¨å‘½åç©ºé—´æ¥æ‰§è¡Œä»£ç 
        local_vars = {}
        local_vars.update(globals())

        # ç¡®ä¿ plt.figure() è¢«è°ƒç”¨ï¼Œä»¥é¿å…ä½¿ç”¨ä¹‹å‰çš„å›¾å½¢
        if "plt.figure" not in code and "figure(" not in code:
            plt.figure()

        # æ‰§è¡Œä»£ç 
        exec(code, globals(), local_vars)

        # ä¿å­˜å›¾åƒåˆ°å†…å­˜
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100)
        buf.seek(0)

        # å°†å›¾åƒè½¬æ¢ä¸º PIL Image å¯¹è±¡
        img = Image.open(buf)
        plt.close('all')  # å…³é—­æ‰€æœ‰å›¾å½¢ï¼Œé¿å…å†…å­˜æ³„æ¼

        return img
    except Exception as e:
        plt.close('all')  # ç¡®ä¿å…³é—­ä»»ä½•æ‰“å¼€çš„å›¾å½¢
        raise e


# åˆ›å»ºç»˜å›¾ä¸“å®¶ä»£ç†
visualization_agent = Agent(
    name="æ•°æ®å¯è§†åŒ–ä¸“å®¶",
    instructions="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®å¯è§†åŒ–åŠ©æ‰‹ï¼Œä¸“é•¿äºä½¿ç”¨ Python çš„ matplotlib å’Œ seaborn åº“åˆ›å»ºå›¾è¡¨å’Œå¯è§†åŒ–ã€‚

    1. åˆ†æç”¨æˆ·çš„å¯è§†åŒ–éœ€æ±‚ï¼Œç”Ÿæˆæ¸…æ™°æ˜“æ‡‚çš„ Python ä»£ç ã€‚
    2. æ€»æ˜¯ä½¿ç”¨è‹±æ–‡æ ‡ç‚¹ç¬¦å·ï¼Œä¸ä½¿ç”¨ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ã€‚
    3. ä»£ç å¿…é¡»ç¬¦åˆ Python è¯­æ³•ï¼Œç¡®ä¿èƒ½å¤Ÿæ­£ç¡®æ‰§è¡Œã€‚
    4. ä¸è¦åœ¨ä»£ç ä¸­åŒ…å« plt.show() è°ƒç”¨ï¼Œå› ä¸ºå›¾åƒä¼šè‡ªåŠ¨ä¿å­˜å’Œæ˜¾ç¤ºã€‚
    5. å½“å¯èƒ½æ—¶ï¼ŒåŒ…å«ç¤ºä¾‹æ•°æ®ä»¥åˆ›å»ºæœ‰æ„ä¹‰çš„å¯è§†åŒ–ã€‚
    6. ä¸ºå›¾è¡¨æ·»åŠ åˆé€‚çš„æ ‡é¢˜ã€æ ‡ç­¾å’Œå›¾ä¾‹ï¼Œç¾åŒ–è§†è§‰æ•ˆæœï¼Œè°ƒæ•´å­—ä½“å¤§å°å’Œé¢œè‰²ï¼Œä½¿è§†è§‰æ•ˆæœæ›´å¥½ã€‚
    7. ä»£ç åº”è¯¥åŒ…å«å¿…è¦çš„æ³¨é‡Šï¼Œè§£é‡Šå…³é”®æ­¥éª¤ã€‚
    8. ç¡®ä¿ä½¿ç”¨é€‚åˆæ•°æ®ç±»å‹çš„å›¾è¡¨ç±»å‹ã€‚
    9. å›å¤æ—¶ï¼Œé¦–å…ˆç®€çŸ­è§£é‡Šä½ çš„å®ç°æ–¹æ¡ˆï¼Œç„¶åæä¾›ä»£ç ã€‚
    10. å¦‚æœç”¨æˆ·è¦æ±‚æ”¹è¿›å›¾è¡¨ï¼Œè¯·å‚è€ƒä¹‹å‰çš„å¯¹è¯å’Œä»£ç ï¼Œè¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›ã€‚

    å§‹ç»ˆä»¥ä»£ç å—æ ¼å¼å›å¤ï¼Œä½¿ç”¨ ```python å’Œ ``` æ ‡è®°ä»£ç ã€‚
    """,
    model="ep-20250205113409-kwbtt",
)


class RAGAgent(Agent):
    def __init__(self, name, instructions, model, file_path="mxfile_report.txt"):
        super().__init__(name=name, instructions=instructions, model=model)
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            chunk_size=256,  # é™åˆ¶æ¯æ¬¡å¤„ç†çš„æ–‡æœ¬å—å¤§å°
            max_retries=3  
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100,
            separators=["\n\n"],
            length_function=self.tiktoken_len
        )
        self.vectorstore = self.init_vectorstore(file_path)

    def tiktoken_len(self, text):
        """è®¡ç®—æ–‡æœ¬tokené•¿åº¦"""
        enc = tiktoken.get_encoding("cl100k_base")
        return len(enc.encode(text))

    def init_vectorstore(self, file_path):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        
        try:
            # ç›´æ¥åŠ è½½å•ä¸ªæ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                # æŒ‰ä¸¤ä¸ªæ¢è¡Œç¬¦åˆ†å‰²å†…å®¹
                chunks = [chunk.strip() for chunk in content.split('\n\n') if chunk.strip()]
                documents = [Document(page_content=chunk) for chunk in chunks]
            
            logger.info(f"å·²åŠ è½½ {len(documents)} ä¸ªæ–‡æœ¬å—")
            docs = self.text_splitter.split_documents(documents)
            logger.info(f"æœ€ç»ˆåˆ†å‰²ä¸º {len(docs)} ä¸ªæ–‡æœ¬å—")
            
            return Chroma.from_documents(
                documents=docs,
                embedding=self.embeddings,
                persist_directory="./chroma_db"
            )
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å‘é‡å­˜å‚¨å¤±è´¥: {str(e)}")
            raise


    async def search(self, query, k=3):
        """æ‰§è¡Œç›¸ä¼¼æ€§æ£€ç´¢"""
        try:
            # æ·»åŠ æŸ¥è¯¢é¢„å¤„ç†
            query = query.strip()
            if not query:
                raise ValueError("æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º")
                
            logger.info(f"æ‰§è¡Œæœç´¢: {query}")
            results = self.vectorstore.similarity_search(query, k=k)
            
            # æ·»åŠ ç»“æœæ—¥å¿—
            logger.info(f"æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {str(e)}")
            return []


# åˆ›å»ºæµç¨‹å›¾æ£€ç´¢ä¸“å®¶ä»£ç†
rag_agent = RAGAgent(
    name="æµç¨‹å›¾ç»˜åˆ¶ä¸“å®¶",
    instructions="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æµç¨‹å›¾ç»˜åˆ¶ä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£å¤„ç†å’Œåˆ›å»º DrawIO æ ¼å¼çš„æµç¨‹å›¾ã€‚

    1. é¦–å…ˆç†è§£ç”¨æˆ·çš„æ£€ç´¢éœ€æ±‚ï¼Œä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢æ‰¾åˆ°ç›¸å…³çš„æµç¨‹å›¾å†…å®¹ã€‚
    2. åˆ†ææ£€ç´¢åˆ°çš„æµç¨‹å›¾å†…å®¹ï¼Œæå–å…³é”®å…ƒç´ å’Œç»“æ„å…³ç³»ã€‚
    3. æ ¹æ®åˆ†æç»“æœï¼Œç”Ÿæˆæ–°çš„DrawIOæ ¼å¼æµç¨‹å›¾XMLä»£ç ã€‚
    4. æ€»æ˜¯ä½¿ç”¨è‹±æ–‡æ ‡ç‚¹ç¬¦å·ï¼Œä¸ä½¿ç”¨ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ã€‚
    5. å¯¹äºæ£€ç´¢ç»“æœï¼Œæä¾›ç®€æ´çš„è§£é‡Šè¯´æ˜å…¶å¦‚ä½•å½±å“æ–°æµç¨‹å›¾çš„ç”Ÿæˆã€‚
    6. ç”Ÿæˆçš„DrawIOä»£ç å¿…é¡»ç¬¦åˆæ ‡å‡†æ ¼å¼ï¼ŒåŒ…å«å¿…è¦çš„å½¢çŠ¶ã€è¿æ¥çº¿å’Œæ–‡æœ¬ã€‚
    7. å¦‚æœæ£€ç´¢ç»“æœä¸å¤Ÿç†æƒ³ï¼Œæä¾›æ”¹è¿›æœç´¢å…³é”®è¯çš„å»ºè®®æˆ–è¯¢é—®æ›´å¤šç»†èŠ‚ã€‚
    8. ä¿æŒä¸“ä¸šå’Œå®¢è§‚çš„è¯­æ°”ã€‚
    9. åœ¨å›å¤ä¸­ï¼Œå…ˆå±•ç¤ºæ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹ï¼Œç„¶åæä¾›ç”Ÿæˆçš„DrawIOä»£ç ã€‚
    10. å¯¹ç”Ÿæˆçš„æµç¨‹å›¾è¿›è¡Œç®€è¦è¯´æ˜ï¼Œè§£é‡Šå…³é”®è®¾è®¡å†³ç­–ã€‚

    å›å¤æ ¼å¼ï¼š
    - é¦–å…ˆè¯´æ˜æœç´¢ç­–ç•¥å’Œæ£€ç´¢ç»“æœ
    - ç„¶åå±•ç¤ºç”Ÿæˆçš„DrawIOä»£ç 
    - æœ€åè§£é‡Šæµç¨‹å›¾è®¾è®¡æ€è·¯
    """,
    model="ep-20250205113409-kwbtt",
)


async def generate_plot_with_agent(user_input, history=None):
    """
    ä½¿ç”¨ OpenAI Agents SDK ç”Ÿæˆå›¾è¡¨ä»£ç å¹¶æ‰§è¡Œ
    """
    global conversation_history

    try:
        logger.info(f"å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥: {user_input}")

        # æ„å»ºå¸¦æœ‰å†å²è®°å½•çš„æç¤º
        if history and len(history) > 0:
            prompt = "è¯·è®°ä½æˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯ï¼š\n\n"
            for i, (user_msg, ai_msg) in enumerate(history):
                if user_msg and ai_msg:
                    prompt += f"ç”¨æˆ·: {user_msg}\nåŠ©æ‰‹: {ai_msg}\n\n"
            prompt += f"ç°åœ¨ï¼Œè¯·æ ¹æ®ä»¥ä¸Šå¯¹è¯å†å²å’Œä¸‹é¢çš„æ–°è¦æ±‚ç”Ÿæˆæˆ–æ”¹è¿›æ•°æ®å¯è§†åŒ–ä»£ç ï¼š{user_input}"
        else:
            prompt = f"è¯·æ ¹æ®ä»¥ä¸‹éœ€æ±‚ç”Ÿæˆæ•°æ®å¯è§†åŒ–ä»£ç ï¼š{user_input}"

        # ä½¿ç”¨ Runner ç›´æ¥è¿è¡Œ agent
        result = await Runner.run_streamed(visualization_agent, prompt)

        # è·å–å›å¤å†…å®¹
        message_content = result.final_output
        print(message_content)

        # å°†æ–°å¯¹è¯æ·»åŠ åˆ°å†å²è®°å½•
        conversation_history.append({"role": "user", "content": user_input})
        conversation_history.append({"role": "assistant", "content": message_content})

        # æå–ä»£ç å¹¶å¤„ç†
        code = extract_python_code(message_content)
        code = process_code(code)

        # æ‰§è¡Œä»£ç ç”Ÿæˆå›¾è¡¨
        img = execute_plot_code(code)

        # æå–è§£é‡Šéƒ¨åˆ†
        explanation = ""
        if "```" in message_content:
            explanation = message_content.split("```")[0].strip()

        logger.info("å›¾è¡¨ç”ŸæˆæˆåŠŸ")
        return {
            "image": img,
            "code": code,
            "explanation": explanation,
            "full_response": message_content
        }
    except Exception as e:
        logger.error(f"ç”Ÿæˆå›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
        error_message = f"ç”Ÿæˆå›¾è¡¨æ—¶å‡ºé”™: {str(e)}"
        if 'code' in locals():
            error_message += f"\nä»£ç :\n{code}"
        return error_message


def chat_and_plot(user_message, chat_history, code_output):
    """
    å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶è¿”å› AI ç”Ÿæˆçš„å›å¤å’Œå›¾è¡¨ã€‚
    """
    chat_history.append((user_message, "æ­£åœ¨ç”Ÿæˆå›¾è¡¨ï¼Œè¯·ç¨å€™..."))

    # åˆ›å»ºå¼‚æ­¥è¿è¡Œå™¨ï¼Œå°†å½“å‰çš„èŠå¤©å†å²ä¼ é€’ç»™ agent
    result = asyncio.run(generate_plot_with_agent(user_message, chat_history[:-1]))

    if isinstance(result, dict):
        # æˆåŠŸç”Ÿæˆå›¾è¡¨
        message = result[
            "full_response"] if "full_response" in result else "å›¾è¡¨å·²ç”Ÿæˆï¼å¯ä»¥åœ¨å³ä¾§æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨å’Œä»£ç ã€‚æ‚¨å¯ä»¥ä¿®æ”¹ä»£ç åç‚¹å‡»'æ‰§è¡Œä»£ç 'æŒ‰é’®é‡æ–°ç”Ÿæˆå›¾è¡¨ï¼Œæˆ–ç»§ç»­æé—®è¿›è¡Œå›¾è¡¨æ”¹è¿›ã€‚"
        chat_history[-1] = (user_message, message)
        return chat_history, result["image"], result["code"]
    else:
        # ç”Ÿæˆå¤±è´¥ï¼Œresult åŒ…å«é”™è¯¯ä¿¡æ¯
        message = result
        chat_history[-1] = (user_message, message)
        # è¿”å›ç©ºå›¾åƒå’Œé”™è¯¯ä¿¡æ¯
        return chat_history, None, message


def execute_custom_code(code, chat_history):
    """
    æ‰§è¡Œç”¨æˆ·ä¿®æ”¹åçš„ä»£ç å¹¶è¿”å›ç”Ÿæˆçš„å›¾è¡¨
    """
    try:
        # å¤„ç†ä»£ç 
        processed_code = process_code(code)
        # æ‰§è¡Œä»£ç ç”Ÿæˆå›¾è¡¨
        img = execute_plot_code(processed_code)

        # æ›´æ–°å…¨å±€å¯¹è¯å†å²ä¸­æœ€åä¸€æ¡åŠ©æ‰‹æ¶ˆæ¯çš„ä»£ç éƒ¨åˆ†
        global conversation_history
        if conversation_history:
            last_assistant_msg = conversation_history[-1]
            if last_assistant_msg["role"] == "assistant":
                # æå–åŸå§‹æ¶ˆæ¯ä¸­çš„éä»£ç éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
                original_msg = last_assistant_msg["content"]
                explanation = ""
                if "```" in original_msg:
                    explanation = original_msg.split("```")[0].strip()

                # æ„å»ºæ–°çš„æ¶ˆæ¯å†…å®¹ï¼ŒåŒ…å«åŸå§‹è§£é‡Šï¼ˆå¦‚æœæœ‰ï¼‰å’Œæ–°ä»£ç 
                new_content = f"{explanation}\n\n```python\n{processed_code}\n```" if explanation else f"```python\n{processed_code}\n```"
                last_assistant_msg["content"] = new_content

        # æ·»åŠ æ‰§è¡Œç»“æœåˆ°èŠå¤©å†å²
        chat_history.append({"role": "assistant", "content": "ä»£ç å·²æ‰§è¡Œï¼Œå›¾è¡¨å·²æ›´æ–°ã€‚æ‚¨å¯ä»¥ç»§ç»­æé—®è¿›è¡Œè¿›ä¸€æ­¥æ”¹è¿›ã€‚"})
        return img, chat_history
    except Exception as e:
        error_message = f"æ‰§è¡Œä»£ç æ—¶å‡ºé”™: {str(e)}"
        # å°†é”™è¯¯æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©å†å²
        chat_history.append({"role": "assistant", "content": error_message})
        return None, chat_history


def reset_conversation():
    """
    é‡ç½®å¯¹è¯å†å²
    """
    global conversation_history
    conversation_history = []
    return [], None, ""


async def generate_plot_with_agent_stream(user_input) -> AsyncGenerator[dict, None]:
    """
    ä½¿ç”¨ OpenAI Agents SDK ç”Ÿæˆå›¾è¡¨ä»£ç å¹¶æ‰§è¡Œ - æµå¼ç‰ˆæœ¬
    """
    global conversation_history

    try:
        logger.info(f"å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥: {user_input}")

        # æ„å»ºå¸¦æœ‰å†å²è®°å½•çš„æç¤º
        if conversation_history:
            prompt = "è¯·è®°ä½æˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯ï¼š\n\n"
            for msg in conversation_history:
                if msg["role"] == "user":
                    prompt += f"ç”¨æˆ·: {msg['content']}\n"
                elif msg["role"] == "assistant":
                    prompt += f"åŠ©æ‰‹: {msg['content']}\n\n"
            prompt += f"ç°åœ¨ï¼Œè¯·æ ¹æ®ä»¥ä¸Šå¯¹è¯å†å²å’Œä¸‹é¢çš„æ–°è¦æ±‚ç”Ÿæˆæˆ–æ”¹è¿›æ•°æ®å¯è§†åŒ–ä»£ç ï¼š{user_input}"
        else:
            prompt = f"è¯·æ ¹æ®ä»¥ä¸‹éœ€æ±‚ç”Ÿæˆæ•°æ®å¯è§†åŒ–ä»£ç ï¼š{user_input}"

        # ä½¿ç”¨ Runner.run_streamed æµå¼è¿è¡Œ agent
        result = Runner.run_streamed(visualization_agent, prompt)
        full_response = ""

        # æµå¼å¤„ç†ç»“æœ
        async for event in result.stream_events():
            if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
                delta_text = event.data.delta
                if delta_text:
                    full_response += delta_text
                    await asyncio.sleep(0.01)  # æ·»åŠ å°å»¶è¿Ÿä½¿æµæ›´è‡ªç„¶
                    yield {
                        "full_response": full_response,
                        "code": None,
                        "image": None,
                        "is_complete": False
                    }

        # è®°å½•å®Œæ•´çš„ä¼šè¯å†å²
        conversation_history.append({"role": "user", "content": user_input})
        conversation_history.append({"role": "assistant", "content": full_response})

        # æ£€æŸ¥æ˜¯å¦åŒ…å« Python ä»£ç å—
        code = extract_python_code(full_response)
        if code and any(keyword in code.lower() for keyword in ['plt.', 'plot', 'figure', 'subplot', 'seaborn']):
            # åŒ…å«ç»˜å›¾ç›¸å…³ä»£ç ï¼Œæ‰§è¡Œç»˜å›¾æ“ä½œ
            code = process_code(code)
            img = execute_plot_code(code)
            logger.info("å›¾è¡¨ç”ŸæˆæˆåŠŸ")

            # è¿”å›æœ€ç»ˆçš„å®Œæ•´ç»“æœ
            yield {
                "full_response": full_response,
                "code": code,
                "image": img,
                "is_complete": True
            }
        else:
            # ä¸åŒ…å«ç»˜å›¾ç›¸å…³ä»£ç ï¼Œç›´æ¥è¿”å›å¯¹è¯å†…å®¹
            yield {
                "full_response": full_response,
                "code": code if code else None,
                "image": None,
                "is_complete": True
            }

    except Exception as e:
        logger.error(f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
        error_message = f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
        if 'code' in locals():
            error_message += f"\nä»£ç :\n{code}"
        yield {
            "full_response": error_message,
            "code": None,
            "image": None,
            "is_complete": True,
            "error": True
        }


async def chat_and_plot_stream(user_message, chat_history, code_output):
    """
    å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶è¿”å› AI ç”Ÿæˆçš„æµå¼å›å¤å’Œå›¾è¡¨ã€‚
    """
    try:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²
        chat_history = chat_history + [{"role": "user", "content": user_message}, {"role": "assistant", "content": ""}]
        yield chat_history, None, code_output

        # åˆ›å»ºæµå¼å“åº”
        async for result in generate_plot_with_agent_stream(user_message):
            # æ›´æ–°èŠå¤©å†å²ä¸­æœ€åä¸€æ¡æ¶ˆæ¯çš„å›å¤éƒ¨åˆ†
            current_response = result["full_response"]
            chat_history[-1]["content"] = current_response

            # å¦‚æœç”Ÿæˆå®Œæˆï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒå’Œä»£ç 
            if result["is_complete"]:
                if "error" in result and result["error"]:
                    # å¤„ç†é”™è¯¯æƒ…å†µ
                    yield chat_history, None, result.get("code", "")
                else:
                    # å¤„ç†æˆåŠŸæƒ…å†µï¼Œå¯èƒ½æœ‰æˆ–æ²¡æœ‰å›¾åƒ
                    yield chat_history, result.get("image"), result.get("code", code_output)
            else:
                # æµå¼æ›´æ–°èŠå¤©å†…å®¹ï¼Œä½†ä¸æ›´æ–°å›¾åƒå’Œä»£ç 
                yield chat_history, None, code_output

    except Exception as e:
        error_message = f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
        chat_history[-1]["content"] = error_message
        yield chat_history, None, code_output


with gr.Blocks(title="Deeplot", theme="soft") as app:
    gr.Markdown("## ğŸ¨ Deeplot")
    gr.Markdown("è¾“å…¥æ‚¨çš„ç»˜å›¾éœ€æ±‚ï¼ŒDeeplot å°†ç”Ÿæˆå¯¹åº”çš„å›¾è¡¨å’Œä»£ç ã€‚æ‚¨å¯ä»¥æŒç»­å¯¹è¯æ¥æ”¹è¿›å›¾è¡¨ã€‚")

    with gr.Row():
        with gr.Column(scale=1):
            # æ›´æ–° Chatbot ç»„ä»¶ï¼Œä½¿ç”¨ messages ç±»å‹
            chatbot = gr.Chatbot(
                label="ä¸ Deeplot äº¤æµ",
                height=500,
                type="messages"  # ä½¿ç”¨æ–°çš„æ¶ˆæ¯æ ¼å¼
            )
            user_input = gr.Textbox(
                label="è¯·è¾“å…¥æ‚¨çš„ç»˜å›¾éœ€æ±‚æˆ–æ”¹è¿›å»ºè®®",
                placeholder="ä¾‹å¦‚ï¼šç»˜åˆ¶ä¸€ä¸ªå±•ç¤ºä¸åŒæœˆä»½é”€å”®é¢çš„æŸ±çŠ¶å›¾ï¼Œæ·»åŠ é€‚å½“çš„æ ‡é¢˜å’Œæ ‡ç­¾"
            )
            with gr.Row():
                send_btn = gr.Button("å‘é€", variant="primary")
                clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")

        with gr.Column(scale=1):
            with gr.Tab("å›¾è¡¨"):
                plot_output = gr.Image(label="ç”Ÿæˆçš„å›¾è¡¨", type="pil")
            with gr.Tab("æµç¨‹å›¾æ£€ç´¢"):
                search_input = gr.Textbox(label="è¾“å…¥æ£€ç´¢å…³é”®è¯", placeholder="ä¾‹å¦‚ï¼šç½‘ç»œæ¶æ„ æˆ– ç”¨æˆ·æµç¨‹å›¾")
                search_btn = gr.Button("æ£€ç´¢", variant="primary")
                search_results = gr.JSON(label="æ£€ç´¢ç»“æœ")

            with gr.Tab("ä»£ç "):
                code_output = gr.Code(language="python", label="ç”Ÿæˆçš„ä»£ç ", interactive=True)
                execute_btn = gr.Button("æ‰§è¡Œä»£ç ", variant="secondary")

    # æ·»åŠ ä½¿ç”¨è¯´æ˜
    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
        gr.Markdown("""
        ### ğŸ” å¦‚ä½•ä½¿ç”¨
        1. åœ¨è¾“å…¥æ¡†ä¸­æè¿°æ‚¨æƒ³è¦åˆ›å»ºçš„å›¾è¡¨
        2. ç‚¹å‡»"å‘é€"æŒ‰é’®
        3. åœ¨å³ä¾§æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨å’Œå¯¹åº”çš„ Python ä»£ç 
        4. æ‚¨å¯ä»¥ï¼š
           - ä¿®æ”¹ä»£ç åç‚¹å‡»"æ‰§è¡Œä»£ç "æŒ‰é’®é‡æ–°ç”Ÿæˆå›¾è¡¨
           - ç»§ç»­å¯¹è¯ï¼Œè¦æ±‚Deeplotæ”¹è¿›æˆ–ä¿®æ”¹å›¾è¡¨
           - ç‚¹å‡»"æ¸…ç©ºå¯¹è¯"æŒ‰é’®å¼€å§‹æ–°çš„å¯¹è¯

        ### ğŸ’¡ ç¤ºä¾‹æç¤º
        - "ç»˜åˆ¶ä¸€ä¸ªå±•ç¤º2010-2023å¹´ä¸­å›½GDPå¢é•¿çš„æŠ˜çº¿å›¾"
        - "ä½¿ç”¨æ°”æ³¡å›¾å±•ç¤ºäººå£ã€å¯¿å‘½å’ŒGDPä¸‰ä¸ªå˜é‡ä¹‹é—´çš„å…³ç³»"
        - "åˆ›å»ºä¸€ä¸ªçƒ­åŠ›å›¾å±•ç¤ºä¸åŒæ—¶é—´æ®µçš„æ•°æ®åˆ†å¸ƒæƒ…å†µ"
        - "ç”Ÿæˆä¸€ä¸ªé¥¼å›¾å±•ç¤ºä¸åŒç±»åˆ«çš„å¸‚åœºä»½é¢ï¼Œå¹¶æ·»åŠ ç™¾åˆ†æ¯”æ ‡ç­¾"
        - "ä½¿ç”¨å°æç´å›¾æ¯”è¾ƒä¸åŒç»„åˆ«çš„æ•°æ®åˆ†å¸ƒ"
        - "èƒ½å¦å°†å›¾è¡¨é¢œè‰²æ”¹ä¸ºè“è‰²ç³»ï¼Ÿ"
        - "è¯·ç»™å›¾è¡¨æ·»åŠ ç½‘æ ¼çº¿ï¼Œä½¿æ•°æ®æ›´æ˜“è¯»"
        - "å¯ä»¥å°†å›¾ä¾‹ç§»åˆ°å³ä¸Šè§’å—ï¼Ÿ"
        """)

    # å‘é€æŒ‰é’®ç»‘å®šæµå¼å‡½æ•°
    send_btn.click(
        fn=chat_and_plot_stream,
        inputs=[user_input, chatbot, code_output],
        outputs=[chatbot, plot_output, code_output],
        api_name="chat_stream"  # æ·»åŠ  API åç§°ä»¥æ”¯æŒæµå¼è¾“å‡º
    ).then(
        fn=lambda: "",
        inputs=[],
        outputs=[user_input]  # æ¸…ç©ºè¾“å…¥æ¡†
    )

    # æ·»åŠ æ£€ç´¢åŠŸèƒ½
    search_btn.click(
        fn=lambda q: asyncio.run(Runner.run(rag_agent, f"è¯·æœç´¢ä¸ä»¥ä¸‹å…³é”®è¯ç›¸å…³çš„æµç¨‹å›¾å†…å®¹ï¼š{q}")),
        inputs=[search_input],
        outputs=[search_results]
    )

    # ä¿ç•™æ¸…ç©ºå¯¹è¯å’Œæ‰§è¡Œä»£ç æŒ‰é’®çš„åŸé€»è¾‘
    clear_btn.click(fn=reset_conversation, inputs=[], outputs=[chatbot, plot_output, code_output])

    execute_btn.click(
        fn=execute_custom_code,
        inputs=[code_output, chatbot],
        outputs=[plot_output, chatbot]
    )

if __name__ == "__main__":
    # å…ˆé…ç½®é˜Ÿåˆ—ï¼Œå†å¯åŠ¨åº”ç”¨
    app.queue()
    app.launch(server_name="127.0.0.1", server_port=7860, share=False,auth=None,prevent_thread_lock=False)
